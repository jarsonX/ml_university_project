{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Jaros≈Çaw Krzysztofik\n",
        "##Machine Learning and Data Science post-graduate course, 2022\n",
        "###Machine Learning class, University of Economics in Katowice\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Jcrg1-E4c4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM:**\n",
        "Create a credit card approval classifier. Test different ML algorithms using Train&Test and Cross-validation methods.\n",
        "\n",
        "**DATA:** Credit Approval Data Set, UCI Machine Learning Repository\n",
        "\n",
        "**SOURCE:** http://archive.ics.uci.edu/ml/datasets/credit+approval"
      ],
      "metadata": {
        "id": "cmBXegMqItM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Libraries"
      ],
      "metadata": {
        "id": "grPk8578SPAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing as prep\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, recall_score, precision_score"
      ],
      "metadata": {
        "id": "TmtX3JPv46pM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load and transform data"
      ],
      "metadata": {
        "id": "dDbG_P_J4wWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"crx.csv\")\n",
        "data = df.to_numpy()"
      ],
      "metadata": {
        "id": "nsYhMk4V43vp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#By exploring the dataset in MS Excel, I have already identified there are missing\n",
        "#values denoted as \"?\". For numeric values I will change those to mean and for\n",
        "#non-numeric to the most frequent value.\n",
        "\n",
        "df = df.replace('?', np.NaN)\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtypes == \"object\":\n",
        "        df = df.fillna(df[col].value_counts().index[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io41d-mz5m71",
        "outputId": "f6a5f2c9-ccee-4262-b39b-0bd36787f3f7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoder = prep.LabelEncoder()\n",
        "\n",
        "for i in range(len(data[0])-1):\n",
        "  data[:,i] = data_encoder.fit_transform(data[:,i])"
      ],
      "metadata": {
        "id": "oZSSbSQX5HcB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Learning"
      ],
      "metadata": {
        "id": "ToKoZdPx6W00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data[:,:-1], data[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
      ],
      "metadata": {
        "id": "cfjprHVX6YR8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Decision Tree"
      ],
      "metadata": {
        "id": "quosHjQ86umB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "wV29K9pf-03X"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation**"
      ],
      "metadata": {
        "id": "jycYGdJ-4iaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier()\n",
        "result = cross_val_score(classifier, X, y, cv=5)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0h9f2Av631z",
        "outputId": "9a7d9091-693d-44fa-d3d8-5907bb854341"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.68115942 0.86231884 0.83333333 0.74637681 0.83211679]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train & Test**"
      ],
      "metadata": {
        "id": "JZHpw88p7wPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(max_depth=3)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nRaport:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q1wfjQA7xnM",
        "outputId": "e0d081e9-550c-42f3-9cc5-29c3390d1109"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raport:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           +       0.89      0.74      0.81       132\n",
            "           -       0.80      0.92      0.85       144\n",
            "\n",
            "    accuracy                           0.83       276\n",
            "   macro avg       0.84      0.83      0.83       276\n",
            "weighted avg       0.84      0.83      0.83       276\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistic regression"
      ],
      "metadata": {
        "id": "dZ7aS1xj9kSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "P4EhCRgh-vs_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In order to use logistic regression, first I need to scale the date. To do so,\n",
        "#some minor transformations are required.\n",
        "\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "data.replace(\"+\", 1, inplace=True)\n",
        "data.replace(\"-\", 0, inplace=True)"
      ],
      "metadata": {
        "id": "MHhLE2zGBkSR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "data = scaler.fit_transform(data)\n",
        "data = scaler.transform(data)"
      ],
      "metadata": {
        "id": "zuEubzmz-yG7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = data[:,:-1], data[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
      ],
      "metadata": {
        "id": "lb3YUsGSCMbn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation**"
      ],
      "metadata": {
        "id": "zdzbXj4H9tdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "result = cross_val_score(classifier, X, y, cv=5)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvNRpwYd9t0R",
        "outputId": "0b26f77d-17f0-4a6e-e3e4-cd8c8f001d77"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.62318841 0.96376812 0.97101449 0.76086957 0.93430657]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train & Test**"
      ],
      "metadata": {
        "id": "1qajjul79uM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"\\nRaport:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUKERz9X9vWA",
        "outputId": "0755d5de-223f-45e7-cafd-73a2f33ce8f7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raport:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.83      0.88       164\n",
            "         1.0       0.79      0.92      0.85       112\n",
            "\n",
            "    accuracy                           0.87       276\n",
            "   macro avg       0.86      0.87      0.86       276\n",
            "weighted avg       0.88      0.87      0.87       276\n",
            "\n"
          ]
        }
      ]
    }
  ]
}